{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Region Proposal network (RPN)\n",
    "2. RPN loss functions\n",
    "3. Region of Interest Pooling (ROI)\n",
    "4. ROI loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feautre Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = torch.zeros((1,3,800,800)).float()\n",
    "\n",
    "# [y1, x1, y2, x2]\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "labels = torch.LongTensor([6, 8])\n",
    "\n",
    "# 1x1 in feature map -> 16x16 in image\n",
    "sub_sample = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "fe = list(model.features)\n",
    "\n",
    "# req_features = fe[:30]\n",
    "req_features = []\n",
    "k = dummy_img.clone()\n",
    "for i in fe:\n",
    "    k = i(k)\n",
    "    if k.size()[2] < 800 // 16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "\n",
    "print(len(req_features))\n",
    "print(out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "faster_rcnn_feature = nn.Sequential(*req_features)\n",
    "sample_output = faster_rcnn_feature(dummy_img)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total anchor #: 9\n",
      "anchor base: \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "-----------------------------------------\n",
      "anchor_box: \n",
      " [[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
      " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
      " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
      " [ -56.        -56.         72.         72.      ]\n",
      " [-120.       -120.        136.        136.      ]\n",
      " [-248.       -248.        264.        264.      ]\n",
      " [ -82.50967   -37.254833   98.50967    53.254833]\n",
      " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
      " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "anchor_number = len(ratios) * len(anchor_scales)\n",
    "print(f'Total anchor #: {anchor_number}')\n",
    "\n",
    "anchor_base = np.zeros((anchor_number ,4), dtype=np.float32)\n",
    "print(f'anchor base: \\n {anchor_base}')\n",
    "print('-----------------------------------------')\n",
    "\n",
    "ctr_y = sub_sample / 2.\n",
    "ctr_x = sub_sample / 2.\n",
    "\n",
    "for idx, (ratio, anchor_scale) in enumerate(itertools.product(ratios, anchor_scales)):\n",
    "    h = sub_sample * anchor_scale * np.sqrt(ratio)\n",
    "    w = sub_sample * anchor_scale * np.sqrt(1. / ratio)\n",
    "    anchor_base[idx, 0] = ctr_y - h / 2 \n",
    "    anchor_base[idx, 1] = ctr_x - w / 2\n",
    "    anchor_base[idx, 2] = ctr_y + h / 2\n",
    "    anchor_base[idx, 3] = ctr_x + w / 2\n",
    "    \n",
    "print(f'anchor_box: \\n {anchor_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "center example: \n",
      " [[ 8.  8.]\n",
      " [24.  8.]\n",
      " [40.  8.]] ....\n",
      "\n",
      "anchor shape:(22500, 4)\n",
      "[[ -37.254834    -82.50966799   53.254834     98.50966799]\n",
      " [ -82.50966799 -173.01933598   98.50966799  189.01933598]\n",
      " [-173.01933598 -354.03867197  189.01933598  370.03867197]\n",
      " ...\n",
      " [ 701.49033201  746.745166    882.50966799  837.254834  ]\n",
      " [ 610.98066402  701.49033201  973.01933598  882.50966799]\n",
      " [ 429.96132803  610.98066402 1154.03867197  973.01933598]]\n"
     ]
    }
   ],
   "source": [
    "fe_size = (800 // 16)  # 피처맵은 50 x 50\n",
    "ctr_x = np.arange(16, (fe_size + 1) * 16, 16)\n",
    "ctr_y = np.arange(16, (fe_size + 1) * 16, 16)\n",
    "\n",
    "anchors = np.zeros((fe_size * fe_size * 9, 4))\n",
    "\n",
    "ctr = np.zeros((len(ctr_x) * len(ctr_y), 2))\n",
    "for idx, (x,y) in enumerate(itertools.product(ctr_x, ctr_y)):\n",
    "    ctr[idx, 1] = x - 8\n",
    "    ctr[idx, 0] = y - 8\n",
    "\n",
    "print(len(ctr))\n",
    "print(f'center example: \\n {ctr[:3]} ....\\n')\n",
    "\n",
    "idx = 0\n",
    "for c_y, c_x in ctr:\n",
    "    for ratio, anchor_scale in itertools.product(ratios, anchor_scales):\n",
    "        h = sub_sample * anchor_scale * np.sqrt(ratio)\n",
    "        w = sub_sample * anchor_scale * np.sqrt(1. / ratio)\n",
    "        anchors[idx, 0] = c_y - h / 2 \n",
    "        anchors[idx, 1] = c_x - w / 2\n",
    "        anchors[idx, 2] = c_y + h / 2\n",
    "        anchors[idx, 3] = c_x + w / 2 \n",
    "        idx += 1\n",
    "        \n",
    "print(f'anchor shape:{anchors.shape}')\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "- IoU가 0.7 이상인 anchor는 positive, 0.3 이하인 anchor는 negative label을 부여한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid anchor counts: (8940,)\n",
      "anchor labels:(8940,)\n",
      "valid anchor shape:(8940, 4)\n"
     ]
    }
   ],
   "source": [
    "bbox = np.array([[20,30,400,500],[300,400,500,600]], dtype=np.float32)\n",
    "labels = np.asarray([6, 8], dtype=np.int8) # 0 represents background\n",
    "\n",
    "inside_index = np.where((anchors[:,0] >=0) &\n",
    "                        (anchors[:,1] >=0) &\n",
    "                        (anchors[:,2] <=800) &\n",
    "                        (anchors[:,3] <=800))[0]\n",
    "print(f'valid anchor counts: {inside_index.shape}')\n",
    "\n",
    "label = np.empty((len(inside_index),), dtype=np.int32)\n",
    "label.fill(-1)\n",
    "print(f'anchor labels:{label.shape}')\n",
    "\n",
    "valid_anchor_boxes = anchors[inside_index]\n",
    "print(f'valid anchor shape:{valid_anchor_boxes.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(bbox, anchor):\n",
    "    ya1, xa1, ya2, xa2 = anchor\n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    yb1, xb1, yb2, xb2 = bbox\n",
    "    box_area = (yb2 - yb1) * (xb2 - xb1)\n",
    "    inter_x1 = max([xb1, xa1])\n",
    "    inter_x2 = min([xb2, xa2])\n",
    "    inter_y1 = max([yb1, ya1])\n",
    "    inter_y2 = min([yb2, ya2])\n",
    "    \n",
    "    if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "        inter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "        iou = inter_area / (anchor_area + box_area - inter_area)\n",
    "    else:\n",
    "        iou = 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox: \n",
      " [[ 20.  30. 400. 500.]\n",
      " [300. 400. 500. 600.]]\n",
      "ious shape: (8940, 2)\n"
     ]
    }
   ],
   "source": [
    "ious = np.zeros((len(valid_anchor_boxes), 2), dtype=np.float32)\n",
    "print(f'bbox: \\n {bbox}')\n",
    "\n",
    "for idx, anchor in enumerate(valid_anchor_boxes):\n",
    "    iou1 = IoU(bbox[0], anchor)\n",
    "    iou2 = IoU(bbox[1], anchor)\n",
    "    ious[idx] = [iou1, iou2]\n",
    "    \n",
    "print(f'ious shape: {ious.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 5620]\n",
      "[0.68130493 0.61035156]\n",
      "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
      " 6358 6366 6374 6382]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = ious.argmax(axis = 0) # 어떤 gt object가 max iou를 갖는지 알려줌\n",
    "print(gt_argmax_ious) \n",
    "\n",
    "gt_max_ious = ious[gt_argmax_ious, [0, 1]] # max iou 값\n",
    "print(gt_max_ious)\n",
    "\n",
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0] # 가장 높은 iou 값을 같는 gt object들을 알려준다.\n",
    "print(gt_argmax_ious)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis=1) # 두개의 bbox중 iou max값을 갖는 인덱스 위치(argmax_ious)\n",
    "\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious)\n",
    "\n",
    "max_ious = ious[np.arange(len(inside_index)), argmax_ious] # 두개의 bbox중 max iou의 값들의 집합\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label 조건\n",
    "pos_iou_threshold = 0.7 <br>\n",
    "neg_iou_threshold = 0.3  \n",
    "\n",
    "label[max_ious < neg_iou_threshold] = 0 <br>\n",
    "label[gt_argmax_ious] = 1 <br>\n",
    "label[max_ious > pos_iou_threshold] = 1\n",
    "\n",
    "- anchor 박스로 iou 계산 시 너무 많은 negative sample이 나오기 때문에 pos 와 neg 균형을 1:1로 맞추어 주는 작업이 필요  \n",
    "  한장의 이미지 당 random 하게 256개의 anchor를 1대1로 맞춰 학습을 진행한다.  \n",
    "  만약 pos가 128보다 적으면 neg를 padding한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_iou_threshold = 0.7\n",
    "neg_iou_threshold = 0.3\n",
    "\n",
    "label[max_ious < neg_iou_threshold] == 0\n",
    "label[gt_argmax_ious] = 1\n",
    "label[max_ious > pos_iou_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ratio = 0.5\n",
    "n_sample = 256  \n",
    "\n",
    "# positive samples\n",
    "n_pos = pos_ratio * n_sample\n",
    "pos_index = np.where(label == 1)[0]\n",
    "\n",
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace = False)\n",
    "    label[disable_index] = -1\n",
    "\n",
    "# negative samples\n",
    "n_neg = np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " ...\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]]\n"
     ]
    }
   ],
   "source": [
    "max_iou_bbox = bbox[argmax_ious]\n",
    "print(max_iou_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:, 0]\n",
    "width = valid_anchor_boxes[:, 3] - valid_anchor_boxes[:, 1]\n",
    "ctr_y = valid_anchor_boxes[:, 0] + 0.5 * height\n",
    "ctr_x = valid_anchor_boxes[:, 1] + 0.5 * width\n",
    "\n",
    "base_height = max_iou_bbox[:, 2] - max_iou_bbox[:, 0]\n",
    "base_width = max_iou_bbox[:, 3] - max_iou_bbox[:, 1]\n",
    "base_ctr_y = max_iou_bbox[:, 0] + 0.5 * base_height\n",
    "base_ctr_x = max_iou_bbox[:, 1] + 0.5 * base_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHaclG%2FbtqBdUkizUl%2FOzPRkcX2FPJPFmN8BKlzl1%2Fimg.png\" width=\"600\" height=\"400\">\n",
    "\n",
    "- 출처 https://ganghee-lee.tistory.com/37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5855728   2.30914558  0.7415674   1.64727602]\n",
      " [ 0.49718446  2.30914558  0.7415674   1.64727602]\n",
      " [ 0.40879611  2.30914558  0.7415674   1.64727602]\n",
      " ...\n",
      " [-2.50801936 -5.29225232  0.7415674   1.64727602]\n",
      " [-2.59640771 -5.29225232  0.7415674   1.64727602]\n",
      " [-2.68479606 -5.29225232  0.7415674   1.64727602]]\n"
     ]
    }
   ],
   "source": [
    "eps = np.finfo(height.dtype).eps #dtype이 가질수 있는 최소값\n",
    "height = np.maximum(height, eps) # 가능 최소값보다 큰것\n",
    "width = np.maximum(width, eps)\n",
    "\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)\n",
    "\n",
    "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "print(anchor_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final labels:\n",
    "anchor_labels = np.empty((len(anchors),), dtype=label.dtype)\n",
    "anchor_labels.fill(-1)\n",
    "anchor_labels[inside_index] = label\n",
    "\n",
    "# Final locations\n",
    "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:], dtype=anchor_locs.dtype)\n",
    "anchor_locations.fill(0)\n",
    "anchor_locations[inside_index, :] = anchor_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- anchor_locations [N, 4] — [22500, 4]\n",
    "- anchor_labels [N,] — [22500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Resion Proposal Network\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*rQ99lLIs7xTAjTaKHHNatA.png\" width=\"700\" height=\"600\">\n",
    "\n",
    "- A box regrression layer\n",
    "- A box classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "mid_channels = 512\n",
    "in_channels = 512\n",
    "n_anchor = 9        # Number of anchors at each location in the feature map\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "reg_layer = nn.Conv2d(mid_channels, n_anchor*4, 1, 1, 0)\n",
    "cls_layer = nn.Conv2d(mid_channels, n_anchor*2, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1 sliding layer\n",
    "conv1.weight.data.normal_(0, 0.01)\n",
    "conv1.bias.data.zero_()\n",
    "\n",
    "# reg_layer\n",
    "reg_layer.weight.data.normal_(0, 0.01)\n",
    "reg_layer.bias.data.zero_()\n",
    "\n",
    "# cls_layer\n",
    "cls_layer.weight.data.normal_(0, 0.01)\n",
    "cls_layer.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 50, 50]) torch.Size([1, 18, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "x= conv1(sample_output)\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_cls_scores = cls_layer(x)\n",
    "\n",
    "print(pred_anchor_locs.shape, pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n",
      "torch.Size([1, 50, 50, 18])\n",
      "torch.Size([1, 22500])\n",
      "torch.Size([1, 22500, 2])\n"
     ]
    }
   ],
   "source": [
    "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
    "print(pred_anchor_locs.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.permute(0, 2, 3 ,1).contiguous()\n",
    "print(pred_cls_scores.shape)\n",
    "\n",
    "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)\n",
    "print(objectness_score.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.view(1, -1, 2)\n",
    "print(pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_cls_scores와 pred_anchor_locs 는 RPN network의 output 이며 가중치를 업데이트하기 위한 loss <br>\n",
    "pred_cls_scores와 objectness_score 는 proposal layer에 input으로 사용, 추후 RoI 네트워크에 의해 사용되는 제안 집합 생성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating proposals to feed Fast R-CNN network\n",
    "\n",
    "- Weather training_mode or testing mode\n",
    "- nms_thresh\n",
    "- n_train_pre_nms — number of bboxes before nms during training\n",
    "- n_train_post_nms — number of bboxes after nms during training\n",
    "- n_test_pre_nms — number of bboxes before nms during testing\n",
    "- n_test_post_nms — number of bboxes after nms during testing\n",
    "- min_size — minimum height of the object required to create a proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_thresh = 0.7\n",
    "n_train_pre_nms = 12000\n",
    "n_train_post_nms = 2000\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "min_size = 16\n",
    "\n",
    "\n",
    "anc_height = anchors[:, 2] - anchors[:, 0]\n",
    "anc_width = anchors[:, 3] - anchors[:, 1]\n",
    "anc_ctr_y = anchors[:, 0] + 0.5 * anc_height\n",
    "anc_ctr_x = anchors[:, 1] + 0.5 * anc_width\n",
    "\n",
    "pred_anchor_locs_numpy = pred_anchor_locs[0].data.numpy()\n",
    "objectness_score_numpy = objectness_score[0].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = pred_anchor_locs_numpy[:, 0]\n",
    "dx = pred_anchor_locs_numpy[:, 1]\n",
    "dh = pred_anchor_locs_numpy[:, 2]\n",
    "dw = pred_anchor_locs_numpy[:, 3]\n",
    "\n",
    "ctr_y = dy * anc_height + anc_ctr_y\n",
    "ctr_x = dx * anc_width + anc_ctr_x\n",
    "h = np.exp(dh) * anc_height\n",
    "w = np.exp(dw) * anc_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert [ctr_x, ctr_y, h, w] to [y1, x1, y2, x2] format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -39.861942,  -77.231255,   54.963337,  100.58985 ],\n",
       "       [ -77.41494 , -182.63435 ,   97.46352 ,  182.30638 ],\n",
       "       [-177.5977  , -354.01462 ,  190.20793 ,  360.53113 ],\n",
       "       ...,\n",
       "       [ 700.5433  ,  747.29663 ,  881.66046 ,  835.72626 ],\n",
       "       [ 614.21576 ,  705.8609  ,  966.6589  ,  883.4604  ],\n",
       "       [ 420.8336  ,  602.99756 , 1132.7819  ,  967.1268  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# region of interest \n",
    "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype = np.float32)\n",
    "roi[:, 0] = ctr_y - 0.5 * h\n",
    "roi[:, 1] = ctr_x - 0.5 * w\n",
    "roi[:, 2] = ctr_y + 0.5 * h\n",
    "roi[:, 3] = ctr_x + 0.5 * w\n",
    "\n",
    "roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clip the predicted boxes to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.         0.        54.963337 100.58985 ]\n",
      " [  0.         0.        97.46352  182.30638 ]\n",
      " [  0.         0.       190.20793  360.53113 ]\n",
      " ...\n",
      " [700.5433   747.29663  800.       800.      ]\n",
      " [614.21576  705.8609   800.       800.      ]\n",
      " [420.8336   602.99756  800.       800.      ]]\n"
     ]
    }
   ],
   "source": [
    "img_size = (800, 800)\n",
    "roi = roi.clip(0, img_size[0]) # 직사각형인 경우 달라질 수 있음\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4) (22500,)\n",
      "[862 871 493 ...   3  22 462]\n"
     ]
    }
   ],
   "source": [
    "# Remove predicted boxes with either height or width < threshold\n",
    "\n",
    "hs = roi[:, 2] - roi[:, 0]\n",
    "ws = roi[:, 3] - roi[:, 1]\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "roi = roi[keep, :] \n",
    "score = objectness_score_numpy[keep]\n",
    "\n",
    "print(roi.shape, score.shape)\n",
    "\n",
    "order = score.ravel().argsort()[::-1]\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 4)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "# 가장 score가 높은 12000개의 roi 박스만 사용\n",
    "order = order[:n_train_pre_nms]\n",
    "roi = roi[order, :]\n",
    "score = score[order]\n",
    "\n",
    "print(roi.shape)\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 4)\n"
     ]
    }
   ],
   "source": [
    "y1, x1, y2, x2 = roi.T\n",
    "areas = (y2 - y1 + 1) * (x2 - x1 +1)\n",
    "order = score.argsort()[::-1]\n",
    "\n",
    "keep = []\n",
    "\n",
    "while order.size > 0:\n",
    "    i = order[0]\n",
    "    keep.append(i)\n",
    "    \n",
    "    # 计算当前score最大anchor与其他anchor的IOU\n",
    "    yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "    xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "    yy2 = np.maximum(y2[i], y2[order[1:]])\n",
    "    xx2 = np.maximum(y2[i], y2[order[1:]])\n",
    "    \n",
    "    h = np.maximum(0.0, yy2-yy1)\n",
    "    w = np.maximum(0.0, xx2-xx1)\n",
    "    \n",
    "    inter = h*w\n",
    "    iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "    \n",
    "    # IOU threshold\n",
    "    inds = np.where(iou <= nms_thresh)[0]\n",
    "    # 要注意这里inds+1, 是因为加上order[0]\n",
    "    order = order[inds+1]\n",
    "\n",
    "keep = keep[:n_train_post_nms]\n",
    "roi = roi[keep]\n",
    "print(roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
