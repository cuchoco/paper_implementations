{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Region Proposal network (RPN)\n",
    "2. RPN loss functions\n",
    "3. Region of Interest Pooling (ROI)\n",
    "4. ROI loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feautre Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = torch.zeros((1,3,800,800)).float()\n",
    "\n",
    "# [y1, x1, y2, x2]\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]])\n",
    "labels = torch.LongTensor([6, 8])\n",
    "\n",
    "# 1x1 in feature map -> 16x16 in image\n",
    "sub_sample = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "fe = list(model.features)\n",
    "\n",
    "# req_features = fe[:30]\n",
    "req_features = []\n",
    "k = dummy_img.clone()\n",
    "for i in fe:\n",
    "    k = i(k)\n",
    "    if k.size()[2] < 800 // 16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "\n",
    "print(len(req_features))\n",
    "print(out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "faster_rcnn_feature = nn.Sequential(*req_features)\n",
    "sample_output = faster_rcnn_feature(dummy_img)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total anchor #: 9\n",
      "anchor base: \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "-----------------------------------------\n",
      "anchor_box: \n",
      " [[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
      " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
      " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
      " [ -56.        -56.         72.         72.      ]\n",
      " [-120.       -120.        136.        136.      ]\n",
      " [-248.       -248.        264.        264.      ]\n",
      " [ -82.50967   -37.254833   98.50967    53.254833]\n",
      " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
      " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "anchor_number = len(ratios) * len(anchor_scales)\n",
    "print(f'Total anchor #: {anchor_number}')\n",
    "\n",
    "anchor_base = np.zeros((anchor_number ,4), dtype=np.float32)\n",
    "print(f'anchor base: \\n {anchor_base}')\n",
    "print('-----------------------------------------')\n",
    "\n",
    "ctr_y = sub_sample / 2.\n",
    "ctr_x = sub_sample / 2.\n",
    "\n",
    "for idx, (ratio, anchor_scale) in enumerate(itertools.product(ratios, anchor_scales)):\n",
    "    h = sub_sample * anchor_scale * np.sqrt(ratio)\n",
    "    w = sub_sample * anchor_scale * np.sqrt(1. / ratio)\n",
    "    anchor_base[idx, 0] = ctr_y - h / 2 \n",
    "    anchor_base[idx, 1] = ctr_x - w / 2\n",
    "    anchor_base[idx, 2] = ctr_y + h / 2\n",
    "    anchor_base[idx, 3] = ctr_x + w / 2\n",
    "    \n",
    "print(f'anchor_box: \\n {anchor_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "center example: \n",
      " [[ 8.  8.]\n",
      " [24.  8.]\n",
      " [40.  8.]] ....\n",
      "\n",
      "anchor shape:(22500, 4)\n",
      "[[ -37.254834    -82.50966799   53.254834     98.50966799]\n",
      " [ -82.50966799 -173.01933598   98.50966799  189.01933598]\n",
      " [-173.01933598 -354.03867197  189.01933598  370.03867197]\n",
      " ...\n",
      " [ 701.49033201  746.745166    882.50966799  837.254834  ]\n",
      " [ 610.98066402  701.49033201  973.01933598  882.50966799]\n",
      " [ 429.96132803  610.98066402 1154.03867197  973.01933598]]\n"
     ]
    }
   ],
   "source": [
    "fe_size = (800 // 16)  # 피처맵은 50 x 50\n",
    "ctr_x = np.arange(16, (fe_size + 1) * 16, 16)\n",
    "ctr_y = np.arange(16, (fe_size + 1) * 16, 16)\n",
    "\n",
    "anchors = np.zeros((fe_size * fe_size * 9, 4))\n",
    "\n",
    "ctr = np.zeros((len(ctr_x) * len(ctr_y), 2))\n",
    "for idx, (x,y) in enumerate(itertools.product(ctr_x, ctr_y)):\n",
    "    ctr[idx, 1] = x - 8\n",
    "    ctr[idx, 0] = y - 8\n",
    "\n",
    "print(len(ctr))\n",
    "print(f'center example: \\n {ctr[:3]} ....\\n')\n",
    "\n",
    "idx = 0\n",
    "for c_y, c_x in ctr:\n",
    "    for ratio, anchor_scale in itertools.product(ratios, anchor_scales):\n",
    "        h = sub_sample * anchor_scale * np.sqrt(ratio)\n",
    "        w = sub_sample * anchor_scale * np.sqrt(1. / ratio)\n",
    "        anchors[idx, 0] = c_y - h / 2 \n",
    "        anchors[idx, 1] = c_x - w / 2\n",
    "        anchors[idx, 2] = c_y + h / 2\n",
    "        anchors[idx, 3] = c_x + w / 2 \n",
    "        idx += 1\n",
    "        \n",
    "print(f'anchor shape:{anchors.shape}')\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resion Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_channels = 512\n",
    "in_channels = 512\n",
    "n_anchor = 9        # Number of anchors at each location in the feature map\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "reg_layer = nn.Conv2d(mid_channels, n_anchor*4, 1, 1, 0)\n",
    "cls_layer = nn.Conv2d(mid_channels, n_anchor*2, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1 sliding layer\n",
    "conv1.weight.data.normal_(0, 0.01)\n",
    "conv1.bias.data.zero_()\n",
    "\n",
    "# reg_layer\n",
    "reg_layer.weight.data.normal_(0, 0.01)\n",
    "reg_layer.bias.data.zero_()\n",
    "\n",
    "# cls_layer\n",
    "cls_layer.weight.data.normal_(0, 0.01)\n",
    "cls_layer.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 50, 50]) torch.Size([1, 18, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "x= conv1(sample_output)\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_cls_scores = cls_layer(x)\n",
    "\n",
    "print(pred_anchor_locs.shape, pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n",
      "torch.Size([1, 50, 50, 18])\n",
      "torch.Size([1, 22500])\n",
      "torch.Size([1, 22500, 2])\n"
     ]
    }
   ],
   "source": [
    "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
    "print(pred_anchor_locs.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.permute(0, 2, 3 ,1).contiguous()\n",
    "print(pred_cls_scores.shape)\n",
    "\n",
    "objectness_scores = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)\n",
    "print(objectness_scores.shape)\n",
    "\n",
    "pred_cls_scores = pred_cls_scores.view(1, -1, 2)\n",
    "print(pred_cls_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
