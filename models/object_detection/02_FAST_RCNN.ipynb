{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a23dc8f-e520-4e42-a97a-79b52e8baca8",
   "metadata": {},
   "source": [
    "# FAST RCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e4a5e-e87e-4028-a372-333a36eb2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from tqdm import trange\n",
    "\n",
    "ann_dir = '../annotation/annotations/panoptic_val2017.json'\n",
    "root_dir = '../data/val2017/'\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "57f6b96f-317b-42d1-821f-ae564477427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ann_dir, 'r') as f:\n",
    "    temp = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9b2cfeba-33d7-4020-ba9d-54a8b77dd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(ann_dir):\n",
    "    with open(ann_dir, 'r') as f:\n",
    "        temp = json.load(f)\n",
    "    image_list = []\n",
    "    ctg_df = pd.DataFrame(temp['categories'])\n",
    "    id2ctg = dict(ctg_df.set_index('id')['name'])\n",
    "    ctg2id = dict(ctg_df.set_index('name')['id'])\n",
    "    for a in temp['annotations']:\n",
    "        image_id = a['file_name'][:-4]\n",
    "        \n",
    "        bbox = np.stack([i['bbox'] for i in a['segments_info']])\n",
    "        labels = np.asarray([i['category_id'] for i in a['segments_info']])\n",
    "        image_list.append({'image_id': image_id,\n",
    "                           'bbox': bbox,\n",
    "                           'labels': labels})\n",
    "    return np.asanyarray(image_list), id2ctg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b32e9980-507f-4345-b918-16791ab4dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "\n",
    "    # obtain x1, y1, x2, y2 of the intersection\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # compute the width and height of the intersection\n",
    "    w = max(0, x2 - x1 + 1)\n",
    "    h = max(0, y2 - y1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    iou = inter / (box1_area + box2_area - inter)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "deedb13a-a791-4c5a-9ac6-e82872f71cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list, id2dtg = get_items(ann_dir)\n",
    "img_id,bbox,_ = image_list[500].values()\n",
    "img = cv2.imread(f'{root_dir}{img_id}.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(img)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "ssresults = ss.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6ed9d32d-b38f-45da-aed7-50635e9c9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowROIPool(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(output_size)\n",
    "        self.size = output_size\n",
    "\n",
    "    def forward(self, images, rois, roi_idx):\n",
    "        n = rois.shape[0]\n",
    "        h = images.size(2)        # input images should be a tensor\n",
    "        w = images.size(3)\n",
    "        x1 = rois[:,0]\n",
    "        y1 = rois[:,1]\n",
    "        x2 = rois[:,2]\n",
    "        y2 = rois[:,3]\n",
    "\n",
    "        x1 = np.floor(x1 * w).astype(int)\n",
    "        x2 = np.ceil(x2 * w).astype(int)\n",
    "        y1 = np.floor(y1 * h).astype(int)\n",
    "        y2 = np.ceil(y2 * h).astype(int)\n",
    "        \n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            img = images[roi_idx[i]].unsqueeze(0)\n",
    "            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]]\n",
    "            img = self.maxpool(img)\n",
    "            res.append(img)\n",
    "        res = torch.cat(res, dim=0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "83d439c5-8bc5-4691-8925-640e61ea9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        rawnet = torchvision.models.vgg16_bn(pretrained=True)\n",
    "        self.seq = nn.Sequential(*list(rawnet.features.children())[:-1])\n",
    "        self.roipool = SlowROIPool(output_size=(7, 7))\n",
    "        self.feature = nn.Sequential(*list(rawnet.classifier.children())[:-1])\n",
    "\n",
    "        _x = Variable(torch.Tensor(1, 3, 224, 224))\n",
    "        _r = np.array([[0., 0., 1., 1.]])\n",
    "        _ri = np.array([0])\n",
    "        _x = self.feature(self.roipool(self.seq(_x), _r, _ri).view(1, -1))\n",
    "        feature_dim = _x.size(1)\n",
    "        self.cls_score = nn.Linear(feature_dim, N_CLASS+1)\n",
    "        self.bbox = nn.Linear(feature_dim, 4*(N_CLASS+1))\n",
    "        \n",
    "        self.cel = nn.CrossEntropyLoss()\n",
    "        self.sl1 = nn.SmoothL1Loss()\n",
    "\n",
    "    def forward(self, inp, rois, ridx):\n",
    "        res = inp\n",
    "        res = self.seq(res)\n",
    "        res = self.roipool(res, rois, ridx)\n",
    "        res = res.detach()\n",
    "        res = res.view(res.size(0), -1)\n",
    "        feat = self.feature(res)\n",
    "\n",
    "        cls_score = self.cls_score(feat)\n",
    "        bbox = self.bbox(feat).view(-1, N_CLASS+1, 4)\n",
    "        return cls_score, bbox\n",
    "\n",
    "    def calc_loss(self, probs, bbox, labels, gt_bbox):\n",
    "        loss_sc = self.cel(probs, labels)\n",
    "        lbl = labels.view(-1, 1, 1).expand(labels.size(0), 1, 4)\n",
    "        mask = (labels != 0).float().view(-1, 1).expand(labels.size(0), 4)\n",
    "        loss_loc = self.sl1(bbox.gather(1, lbl).squeeze(1) * mask, gt_bbox * mask)\n",
    "        lmb = 1.0\n",
    "        loss = loss_sc + lmb * loss_loc\n",
    "        return loss, loss_sc, loss_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f04739-fa7b-4b5b-9aed-d5f1ea000d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226cea0-2b74-4cb9-a637-4b2979abb791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60288d-a57e-47fd-b430-c729e3990552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601e114-acaf-43aa-a7b3-b3a3ccb410d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
